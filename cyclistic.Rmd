---
output:
  pdf_document: default
  html_document: default
---
```{r setup, include=FALSE}
options(scipen = 999)  # Suppress scientific notation globally
library(tidyverse)
library(lubridate)
library(geosphere)
```
# Cyclistic Bikeshare Case Study
## Importing the CSVs into data frames
``` {r}
dt2019 <- read_csv("Divvy_Trips_2019_Q1.csv")
dt2020 <- read_csv("Divvy_Trips_2020_Q1.csv")
```
## Cleaning 
#### `colnames()` reveals that the dataframes use different variable names for columns'

Datasets are also revealed to use different bucketing systems
-	"Customer/Subscriber"(2019), 
-	"member/casual"2010
2020 & 2019 dates are in different formats
Geospatial data missing from 2019 Data
Trip Duration Data missing from 2020 Data
A calculated distance will be useful for further analysis
```{r Print out imported dataframes, echo=F, eval=F}
print("IMPORTED DATAFRAMES")
colnames(dt2019)
colnames(dt2020)
```

### Renaming & Restructuring for compatibility of dataframes
Calculate: tripduration(calculate)  
Normalize the member_casual(usertype)  
lat&long(2019 missing)  

### Rebucketing member_casual(2020)/usertype(2019), Fixing Date Formats on 2020 DF and Calcualting Trip Duration on 2020 table
```{r}
dt19rebucket <- dt2019 %>%
	mutate(usertype=case_when(usertype=="Subscriber"~"member",TRUE ~ "casual")) 
dt2020_tripduration <- dt2020 %>%
	mutate(tripduration = ended_at-started_at,
		started_at=format(started_at,"%Y-%m-%d %H:%M:%S"),
		ended_at=format(ended_at,"%Y-%m-%d %H:%M:%S")
	)
```

### Renaming vars(2019) for compatibility
```{r}
dt19RenCol <- dt19rebucket %>% rename(
	ride_id=trip_id, 
	started_at=start_time, ended_at=end_time,
	start_station_id=from_station_id,
	start_station_name=from_station_name,
	end_station_id=to_station_id, 
	end_station_name=to_station_name,
	member_casual=usertype) %>% 
	select(ride_id,started_at,ended_at,
		start_station_name,start_station_id,
		end_station_name,end_station_id,
		member_casual,tripduration)
rm(dt19rebucket) 
rm(dt2020)
rm(dt2019)
```


## Reconstruct missing Geospatial Information for 2019 DataFrame  
### Get all station names and locations
```{r Generate list of stations from both tables}
station_ids <- c(
  dt19RenCol$start_station_id,
  dt19RenCol$end_station_id,
  dt2020_tripduration$start_station_id,
  dt2020_tripduration$end_station_id
) 
station_names <- c(
  dt19RenCol$start_station_name,
  dt19RenCol$end_station_name,
  dt2020_tripduration$start_station_name,
  dt2020_tripduration$end_station_name
) 

# Generate The Station/Geospatial List of Stations
station_names_ids <- data.frame(station_id=station_ids,station_name=station_names) %>% 
	filter(!is.na(station_id),!is.na(station_name)) %>% distinct(station_id,.keep_all=T)
station_loc <- data.frame(
	station_id=c(dt2020_tripduration$start_station_id,
		dt2020_tripduration$end_station_id),
	lat=c(dt2020_tripduration$start_lat,
		dt2020_tripduration$end_lat),
	lng=c(dt2020_tripduration$start_lng,
		dt2020_tripduration$end_lng))%>%
        filter(!is.na(station_id),!is.na(lat),!is.na(lng)) %>% 
    distinct(station_id,.keep_all=T)
# Joing the names with the location data 
stations <- station_names_ids %>% inner_join(station_loc,by="station_id") 
```
## Populate the 2019 DF with Geospatial data from the STATIONS DF
```{r}
dt19Geospatial <- dt19RenCol %>% mutate(
start_lat=stations$lat[match(start_station_id,stations$station_id)], start_lng=stations$lng[match(start_station_id,stations$station_id)],
end_lat=stations$lat[match(end_station_id,stations$station_id)],
end_lng=stations$lng[match(end_station_id,stations$station_id)]
) 
```
## Intersect the Common Variables
```{r}
names2019 <- colnames(dt19Geospatial)
names2020 <- colnames(dt2020_tripduration)
common_names <- intersect(names2019, names2020)
```
### Concatenante the 2 dataframes
```{r}
cyclistic <- rbind(dt19Geospatial[common_names],dt2020_tripduration[common_names])
rm(common_names)
rm(names2019)
rm(names2020)
```
### Calculating and adding a tripduration_minutes column
```{r}
cyclistic_tripDurMinutes <- cyclistic %>% mutate(trip_duration_minutes=tripduration/60)
cyclistic <- cyclistic_tripDurMinutes
rm(cyclistic_tripDurMinutes)
```

### Calculate the distances using the haversine formula
```{r Distance Calcualtion}
cyclistic_haversine <- cyclistic %>% mutate(distance=distHaversine(cbind(start_lng,start_lat),cbind(end_lng,end_lat)))
cyclistic <- cyclistic_haversine
rm(cyclistic_haversine)
```
### Calculate the Speed of the trip
```{r}
cyclistic_speed <- cyclistic %>% mutate(speed_kmh = (distance/1000)/(tripduration/3600))
cyclistic <- cyclistic_speed
#rm(cyclistic_speed)
```
### Remove Station 675
675 is the HQ & Warehouse, this data represents Repair & Operations
```{r}
cyclistic_675 <- cyclistic %>% filter(start_station_id!=675) %>% head(n=nrow(.))
cyclistic <- cyclistic_675
rm(cyclistic_675)
```
### Removing Outliers
By creating a new column with `duration_hours_limit` represented as minutes
Some of the trips were several days long and even months
remove anything longer than `duration_hours_limit` days
```{r}
# Mutate tripduration(seconds) into HOURS
duration_hours_limit <-  2 
cyclistic_filtered_outliers <- cyclistic %>%
  mutate( trip_duration_hours = trip_duration_minutes / 60 ) %>%
  filter(trip_duration_hours < duration_hours_limit)
cyclistic <- cyclistic_filtered_outliers
rm(cyclistic_filtered_outliers)
```
### Descriptive Analysis
```{r}
# Mode function
get_mode <- function(x) {
  uniq_vals <- unique(x)
  uniq_vals[which.max(tabulate(match(x, uniq_vals)))]
}
colnames(cyclistic)
head(cyclistic)
str(cyclistic)
## General Shape of the data 
range(cyclistic$started_at)
range(cyclistic$start_station_id)
## Trip Durations
cyclistic%>%summarize(min=min(trip_duration_minutes),max=max(trip_duration_minutes),average=mean(trip_duration_minutes,na.rm=TRUE))

## Trip Distances
cyclistic%>%summarize(min=min(distance,na.rm=T),max=max(distance,na.rm=T),average=mean(distance,na.rm=TRUE))

# Weekday Mode (weekday with most rides)
get_mode(lubridate::wday(cyclistic$started_at,label=T))
```
### Ride Averages per user type 
```{r}
cyclistic %>% group_by(member_casual) %>% summarize(average=mean(tripduration,na.rm=T),min=min(tripduration),max=max(tripduration),mode=get_mode(tripduration))
```

## EXPLORATION
Question: How do members use the service diff than casuals
- Time of day
- trip_duration vs distance?
- weekdays/weekends

### Plot Trip durations vs trip distances
Here we see that there is an overlap in the "leisuriness/rushyness" of the trips taken by members as well as casual users, suggesting that many casual users are using the service to commute. A higher slope angle represents a more leisurely pace while a lower slope angle suggests a more rushed pace. The samples which form a straight vertical line represent trips which ended in the same station that they startedin, suggesting a completely leisurely ride with the highest ones taking the longest.
```{r, eval=T}
 cyclistic[sample(nrow(cyclistic),size=7800),] %>%
	arrange(desc(member_casual))%>%  #Z plot order control
	ggplot(aes(x=distance,y=trip_duration_minutes,color=member_casual))+
	geom_point(size=3)+labs(x="Distance Travelled",y="Trip Duration (minutes)",color="Member Type")
```

### Plot top destination station with the most rushed users
Here we see the destinations with the least lesurly trips(highest speed) and largest number of trips, suggesting a commute destination. These are the best stations to target commuters on the casual tiers.
```{r Busiest most rushed destination stations, eval=TRUE, fig.width=18, fig.height=10, fig.dpi=300 }
topn<-10
cyclistic %>%
  group_by(end_station_id,end_station_name,member_casual) %>%
  summarize(avgSpeed = mean(speed_kmh),tripcount=n()) %>%
  arrange(desc(tripcount),desc(avgSpeed))%>%
	filter(member_casual=="casual")%>%
	head(n=topn)%>%
  ggplot(aes(x = factor(end_station_id), y = avgSpeed,fill=member_casual)) +
  geom_col() +
  geom_text(aes(label=end_station_name,y=avgSpeed-1.3),hjust=0,size=7,angle=-90)+
  geom_label(aes(label=paste0("Station ID\n",end_station_id)),fill="white",vjust=1.2,size=6)+
  geom_label(aes(label=paste0("Number of trips\n",tripcount)),fill="white",vjust=3.5,size=4)+
  scale_y_continuous(n.breaks = 12)+
  labs(title=paste("Top ",topn,"busiest & most rushed destinations by casual riders"),y="Average Speed",x="Number of trips for Q1 2019 & 2020")
```

### Usage by Hour
Here we see that member usage increases at rush hours times suggesting that members generally use the service for daily work commuting.
Also we can see that casual users have a more regular bell-curve distribution centered at around 3pm

The most frequently occuring trips overall are to and from station 192 which is the Adams & canal station, right next to chicago union station this suggests that most trips are part of a daily commute
``` {r Number of trips vs hours,eval=T}
cyclistic %>% 
  mutate(hour = lubridate::hour(started_at)) %>%
  mutate(year = lubridate::year(started_at)) %>%
  # Count by user type and hour
  count(member_casual, hour,year) %>% 
  # Create the plot AFTER all data manipulation
  ggplot(aes(x = hour, y = n, fill = member_casual)) +
  geom_col(position = "dodge")+labs(fill="Membership Type")+
  labs(title="Usage by hour of the day per member types",
	x="24 Hour Scale",y="Number of Trips")
```
	


### Usage by weekday
When usage is measured by weekday we can see that members tend for heavier use during the weekdays and tapering off on the weekends, while casual users are seeing an increase during the weekends, with the highest usage on Sundays.
Suggest that weekend discounts for members might attract more of the weekend casual riders to a membership.
``` {r Number of trips per weekday,eval=TRUE}
cyclistic %>% 
  mutate(weekday = lubridate::wday(started_at,label=T)) %>%
  # Count by user type and hour
  count(member_casual, weekday) %>% 
  # Create the plot AFTER all data manipulation
  ggplot(aes(x = weekday, y = n, fill = member_casual)) +
  geom_col(position = "dodge")+labs(fill="Membership Type",y="Number of Users")+
	scale_y_continuous(labels = function(x) format(x, scientific = FALSE))
```

```{r Useless violin(rework), eval=F,include=FALSE}
cyclistic %>% mutate(date = as.Date(started_at)) %>%
	ggplot(aes(x=member_casual,
		y=n,
		color=member_casual,
		size=n)
	)+
	geom_violin(
		aes(fill=member_casual),
		show.legend=FALSE,
		alpha=0.7,
	)+
	geom_boxplot(fill=NA,color="black",width=0.2)+
	scale_size_continuous(c(1,4))+ 
	theme(legend.position="none",
	axis.ticks.y = element_blank(), 
	axis.text.y = element_blank())
```

``` {r Geographic Plot, eval=FALSE,include=FALSE}
ggplot()+ geom_segment(
	 data=cyclistic,
	 aes(
		 x=start_lng,y=start_lat,
		 xend=end_lng,yend=end_lat,
		 color=as.factor(start_station_id)),alpha=.3, size=.02) +
	geom_point(
		 data=stations,
		 aes(x=lng,y=lat,color=as.factor(station_id)),size=3) +
	geom_label(data=filter(stations,stations$station_id==675),aes(x=lng,y=lat,label=station_id)) + scale_y_continuous(limits=c(41.88,41.9)) + scale_x_continuous(limits=c(-87.7,-87.6))+ theme_dark() + theme(legend.position="none", panel.background = element_rect(fill = 'black'), color = 'purple') #+ scale_color_brewer(palette="RdBu",direction=-1)
```

```{r Knit, eval=FALSE,include=FALSE}
rmarkdown::render("cyclistic.Rmd",output_file="render_cyclistic.html",output_format="html_document")
```
```{r Output To CSV, eval=F,include=FALSE}
write.csv(cyclistic,"cyclistic_result.csv")
```
```{r Deleter of all,eval=F,include=FALSE}
rm(list=ls())
```

